{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cleared-version",
   "metadata": {},
   "source": [
    "# Litterbot\n",
    "\n",
    "Device von CPU auf GPU wechseln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-execution",
   "metadata": {},
   "source": [
    "TRT optimierte Modelle laden.\n",
    "\n",
    "> WICHTIG: Modelle müssen zuerst mit den Notebooks zum Datensammeln und Trainieren erstellt werden. Die Modelle mit der Endung .pth müssen im gleichen Ordner sein, wie dieses Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch2trt import TRTModule\n",
    "\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('best_steering_model_xy_trt.pth')) # well trained road following model\n",
    "\n",
    "model_trt_collision = TRTModule()\n",
    "model_trt_collision.load_state_dict(torch.load('best_model_trt.pth')) # well trained collision avoidance model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-pregnancy",
   "metadata": {},
   "source": [
    "### Pre-Processing Funktion\n",
    "1. Konvertieren von HWC-Layout zu CHW-Layout\n",
    "2. Normalisieren mit denselben Parametern wie beim Training (Kamera liefert Werte im Bereich [0, 255] und die beim Training geladenen Bilder im Bereich [0, 1], so dass um 255,0 skaliert werden muss.\n",
    "3. Übertragen der Daten vom CPU-Speicher in den GPU-Speicher.\n",
    "4. Hinzufügen einer Batch-Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-sydney",
   "metadata": {},
   "source": [
    "Starten der Kamera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "structural-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224, fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-philippines",
   "metadata": {},
   "source": [
    "Erstellen der Roboter Instanz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "altered-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/workspace/muellot_jetbot/jetbot\"))\n",
    "\n",
    "from robot2 import Robot2\n",
    "\n",
    "robot = Robot2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-professional",
   "metadata": {},
   "source": [
    "### Kontrollinterface für den Roboter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "molecular-difficulty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91445386cd1a428caa129f177f1d0fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(ToggleButtons(button_style='danger', description='On / Off', index=1, options=('On', 'Off'), va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1a5d54dc9f4ddb8d0f0f6a51843706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Label(value='Road Following Sliders'), FloatSlider(value=0.0, description='Netwo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "from ipywidgets import Layout, Label\n",
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "image_widget = widgets.Image()\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "on_off_widget = widgets.ToggleButtons(options=['On', 'Off'], button_style='danger', description='On / Off', value='Off')\n",
    "state_widget = widgets.ToggleButtons(options=['Manuell', 'Auto'], description='Camera', value='Manuell')\n",
    "display(widgets.VBox([on_off_widget,state_widget]))\n",
    "\n",
    "#Road Following sliders\n",
    "network_output_slider = widgets.FloatSlider(description='Network Output', min=-1.0, max=1.0, value=0, step=0.01, orientation='horizontal', disabled=False, layout={'width': '400px'})\n",
    "steering_gain_slider  = widgets.FloatSlider(description='Steering Gain', min=-1.0, max=1.0, value=-0.7, step=0.01, orientation='horizontal', layout={'width': '300px'})\n",
    "steering_dgain_slider = widgets.FloatSlider(description='Steering kd', min=0.0, max=0.5, step=0.001, value=0.06, orientation='horizontal', layout={'width': '300px'})\n",
    "steering_bias_slider  = widgets.FloatSlider(description='Steering Bias', min=-0.5, max=0.5, value=0.0, step=0.01, orientation='horizontal', layout={'width': '300px'})\n",
    "steering_value_slider = widgets.FloatSlider(description='Steering', min=-1.0, max=1.0, value=0, step=0.01, orientation='horizontal', disabled=False, layout={'width': '400px'})\n",
    "throttle_slider = widgets.FloatSlider(description='Throttle', min=-1.0, max=1.0, value=0.15, step=0.01, orientation='vertical')\n",
    "\n",
    "#Collision Avoidance sliders\n",
    "blocked_slider = widgets.FloatSlider(description='Blocked', min=0.0, max=1.0, orientation='horizontal')\n",
    "stopduration_slider= widgets.IntSlider(description='Time for Stop', min=1, max=1000, step=1, value=10, orientation='horizontal') \n",
    "blocked_threshold= widgets.FloatSlider(description='Blocked Threshold', min=0, max=1.0, step=0.01, value=0.8, orientation='horizontal')\n",
    "\n",
    "\n",
    "#steering_gain_link   = traitlets.link((steering_gain_slider, 'value'), (robot, 'steering_gain'))\n",
    "#steering_offset_link = traitlets.link((steering_bias_slider, 'value'), (robot, 'steering_offset'))\n",
    "#steering_value_link  = traitlets.link((steering_value_slider, 'value'), (robot, 'steering'))\n",
    "#throttle_slider_link = traitlets.link((throttle_slider, 'value'), (robot, 'throttle'))\n",
    "\n",
    "lout=Layout(align_items='center', border='3px solid black', padding='3px')\n",
    "\n",
    "auto_widgets = widgets.HBox([\n",
    "    widgets.VBox([Label('Road Following Sliders'),\n",
    "        network_output_slider,\n",
    "        steering_gain_slider,\n",
    "        steering_dgain_slider,\n",
    "        steering_bias_slider, \n",
    "        steering_value_slider], \n",
    "        layout = lout\n",
    "        ),\n",
    "    throttle_slider,\n",
    "    image_widget,\n",
    "    widgets.VBox([Label('Collision Avoidance Sliders'),\n",
    "        blocked_slider,\n",
    "        stopduration_slider,\n",
    "        blocked_threshold],\n",
    "        layout = lout)],\n",
    "    layout = lout\n",
    "    )\n",
    "\n",
    "display(auto_widgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "count_stops = 0\n",
    "go_on = 1\n",
    "stop_time = 10 # The number of frames to remain stopped\n",
    "x = 0.0\n",
    "y = 0.0\n",
    "speed_value = throttle_slider.value\n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last, blocked_slider, robot, count_stops, stop_time, go_on, x, y, blocked_threshold\n",
    "    global speed_value, steer_gain, steer_dgain, steer_bias\n",
    "                \n",
    "    steer_gain = steering_gain_slider.value\n",
    "    steer_dgain = steering_dgain_slider.value\n",
    "    steer_bias = steering_bias_slider.value\n",
    "       \n",
    "    image_preproc = preprocess(change['new']).to(device)\n",
    "     \n",
    "    #Collision Avoidance model:\n",
    "    \n",
    "    prob_blocked = float(F.softmax(model_trt_collision(image_preproc), dim=1).flatten()[0])\n",
    "    \n",
    "    blocked_slider.value = prob_blocked    \n",
    "    stop_time=stopduration_slider.value\n",
    "    \n",
    "    if go_on == 1:    \n",
    "        if prob_blocked > blocked_threshold.value: # threshold should be above 0.5\n",
    "            count_stops += 1\n",
    "            go_on = 2\n",
    "        else:\n",
    "            #start of road following detection\n",
    "            go_on = 1\n",
    "            count_stops = 0\n",
    "            xy = model_trt(image_preproc).detach().float().cpu().numpy().flatten()        \n",
    "            x = xy[0]            \n",
    "            y = (0.5 - xy[1]) / 2.0\n",
    "            network_output_slider.value = x\n",
    "            speed_value = speed_control_slider.value\n",
    "    else:\n",
    "        count_stops += 1\n",
    "        if count_stops < stop_time:\n",
    "            x = 0.0 #set x steering to zero\n",
    "            y = 0.0 #set y steering to zero\n",
    "            speed_value = 0 # set speed to zero\n",
    "        else:\n",
    "            go_on = 1\n",
    "            count_stops = 0\n",
    "            \n",
    "    \n",
    "    angle = math.atan2(x, y)        \n",
    "    pid = angle * steer_gain + (angle - angle_last) * steer_dgain\n",
    "    steering_value_slider.value = pid + steer_bias\n",
    "    angle_last = angle\n",
    "    robot.throttle = speed_value\n",
    "    robot.steering = max(min(steering_value_slider.value, 1.0), -1.0) \n",
    "\n",
    "execute({'new': camera.value}) # call the function once to initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(execute, names='value') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "balanced-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-friend",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
